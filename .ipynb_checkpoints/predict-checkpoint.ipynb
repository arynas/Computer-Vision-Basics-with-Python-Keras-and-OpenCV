{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Imports*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # system functions (ie. exiting the program)\n",
    "import os # operating system functions (ie. path building on Windows vs. MacOs)\n",
    "import time # for time operations\n",
    "import uuid # for generating unique file names\n",
    "import math # math functions\n",
    "\n",
    "from IPython.display import display as ipydisplay, Image, clear_output, HTML # for interacting with the notebook better\n",
    "\n",
    "import numpy as np # matrix operations (ie. difference between two matricies)\n",
    "import cv2 # (OpenCV) computer vision functions (ie. tracking)\n",
    "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "print('OpenCV Version: {}.{}.{}'.format(major_ver, minor_ver, subminor_ver))\n",
    "\n",
    "import matplotlib.pyplot as plt # (optional) for plotting and showing images inline\n",
    "%matplotlib inline\n",
    "\n",
    "import keras # high level api to tensorflow (or theano, CNTK, etc.) and useful image preprocessing\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "print('Keras image data format: {}'.format(K.image_data_format()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Constants*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_FOLDER = os.path.join('images') # images for visuals\n",
    "\n",
    "MODEL_PATH = os.path.join('model')\n",
    "MODEL_FILE = os.path.join(MODEL_PATH, 'hand_model_gray.hdf5') # path to model weights and architechture file\n",
    "MODEL_HISTORY = os.path.join(MODEL_PATH, 'model_history.txt') # path to model training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgrtorgb(image):\n",
    "    return cv2.cvtColor(image.copy(), cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jupyter Notebook image display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(name):\n",
    "    \"\"\"\n",
    "    Showing image files.\n",
    "    \"\"\"\n",
    "    fname = os.path.join(IMAGES_FOLDER, name)\n",
    "    ipydisplay(Image(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image, figsize=(8,8), recolour=False):\n",
    "    \"\"\"\n",
    "    Plotting image matricies.\n",
    "    \"\"\"\n",
    "    if recolour: image = bgrtorgb(image)\n",
    "    plt.figure(figsize=figsize)\n",
    "    if image.shape[-1] == 3:\n",
    "        plt.imshow(image)\n",
    "    elif image.shape[-1] == 1 or len(image.shape) == 2:\n",
    "        plt.imshow(image, cmap='gray')\n",
    "    else:\n",
    "        raise Exception(\"Image has invalid shape.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tracker.\n",
    "def setup_tracker(ttype):\n",
    "    tracker_types = ['BOOSTING', 'MIL', 'KCF', 'TLD', 'MEDIANFLOW', 'GOTURN']\n",
    "    tracker_type = tracker_types[ttype]\n",
    "\n",
    "    if tracker_type == 'BOOSTING':\n",
    "        tracker = cv2.TrackerBoosting_create()\n",
    "    if tracker_type == 'MIL':\n",
    "        tracker = cv2.TrackerMIL_create()\n",
    "    if tracker_type == 'KCF':\n",
    "        tracker = cv2.TrackerKCF_create()\n",
    "    if tracker_type == 'TLD':\n",
    "        tracker = cv2.TrackerTLD_create()\n",
    "    if tracker_type == 'MEDIANFLOW':\n",
    "        tracker = cv2.TrackerMedianFlow_create()\n",
    "    if tracker_type == 'GOTURN':\n",
    "        tracker = cv2.TrackerGOTURN_create()\n",
    "    \n",
    "    return tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    0: 'fist',\n",
    "    1: 'five',\n",
    "    2: 'thumbsup',\n",
    "    3: 'yo'\n",
    "}\n",
    "\n",
    "# CURR_POSE = 'five'\n",
    "# DATA = 'training_data'\n",
    "\n",
    "# # Helper function for applying a mask to an array\n",
    "# def mask_array(array, imask):\n",
    "#     if array.shape[:2] != imask.shape:\n",
    "#         raise Exception(\"Shapes of input and imask are incompatible\")\n",
    "#     output = np.zeros_like(array, dtype=np.uint8)\n",
    "#     for i, row in enumerate(imask):\n",
    "#         output[i, row] = array[i, row]\n",
    "#     return output\n",
    "\n",
    "\n",
    "# # Begin capturing video\n",
    "# video = cv2.VideoCapture(1)\n",
    "# if not video.isOpened():\n",
    "#     print(\"Could not open video\")\n",
    "#     sys.exit()\n",
    "\n",
    "\n",
    "# # Read first frame\n",
    "# ok, frame = video.read()\n",
    "# if not ok:\n",
    "#     print(\"Cannot read video\")\n",
    "#     sys.exit()\n",
    "# # Use the first frame as an initial background frame\n",
    "# bg = frame.copy()\n",
    "\n",
    "\n",
    "# # Kernel for erosion and dilation of masks\n",
    "# kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "\n",
    "# # Tracking\n",
    "# # Bounding box -> (TopRightX, TopRightY, Width, Height)\n",
    "# bbox_initial = (60, 60, 170, 170)\n",
    "# bbox = bbox_initial\n",
    "# # Tracking status, -1 for not tracking, 0 for unsuccessful tracking, 1 for successful tracking\n",
    "# tracking = -1\n",
    "\n",
    "\n",
    "# # Text display positions\n",
    "# positions = {\n",
    "#     'hand_pose': (15, 40),\n",
    "#     'fps': (15, 20)\n",
    "# }\n",
    "\n",
    "\n",
    "# # Image count for file name\n",
    "# img_count = 0\n",
    "\n",
    "# # Capture, process, display loop    \n",
    "# while True:\n",
    "#     # Read a new frame\n",
    "#     ok, frame = video.read()\n",
    "#     display = frame.copy()\n",
    "#     if not ok:\n",
    "#         break\n",
    "        \n",
    "        \n",
    "#     # Start timer\n",
    "#     timer = cv2.getTickCount()\n",
    "\n",
    "    \n",
    "#     # Processing\n",
    "#     # First find the absolute difference between the two images\n",
    "#     diff = cv2.absdiff(bg, frame)\n",
    "#     mask = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "#     # Threshold the mask\n",
    "#     th, thresh = cv2.threshold(mask, 10, 255, cv2.THRESH_BINARY)\n",
    "#     # Opening, closing and dilation\n",
    "#     opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "#     closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "#     img_dilation = cv2.dilate(closing, kernel, iterations=2)\n",
    "#     # Get mask indexes\n",
    "#     imask = img_dilation > 0\n",
    "#     # Get foreground from mask\n",
    "#     foreground = mask_array(frame, imask)\n",
    "#     foreground_display = foreground.copy()\n",
    "    \n",
    "    \n",
    "#     # If tracking is active, update the tracker\n",
    "#     if tracking != -1:\n",
    "#         tracking, bbox = tracker.update(foreground)\n",
    "#         tracking = int(tracking)\n",
    "        \n",
    "        \n",
    "#     # Use numpy array indexing to crop the foreground frame\n",
    "#     hand_crop = img_dilation[int(bbox[1]):int(bbox[1]+bbox[3]), int(bbox[0]):int(bbox[0]+bbox[2])]\n",
    "    \n",
    "        \n",
    "#     # Draw bounding box\n",
    "#     p1 = (int(bbox[0]), int(bbox[1]))\n",
    "#     p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "#     cv2.rectangle(foreground_display, p1, p2, (255, 0, 0), 2, 1)\n",
    "#     cv2.rectangle(display, p1, p2, (255, 0, 0), 2, 1)\n",
    "    \n",
    "        \n",
    "#     # Calculate Frames per second (FPS)\n",
    "#     fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)\n",
    "#     # Display FPS on frame\n",
    "#     cv2.putText(foreground_display, \"FPS : \" + str(int(fps)), positions['fps'], cv2.FONT_HERSHEY_SIMPLEX, 0.65, (50, 170, 50), 2)\n",
    "#     cv2.putText(display, \"FPS : \" + str(int(fps)), positions['fps'], cv2.FONT_HERSHEY_SIMPLEX, 0.65, (50, 170, 50), 2)\n",
    "    \n",
    "    \n",
    "#     # Display result\n",
    "#     cv2.imshow(\"display\", display)\n",
    "#     # Display diff\n",
    "#     cv2.imshow(\"diff\", diff)\n",
    "#     # Display thresh\n",
    "#     cv2.imshow(\"thresh\", thresh)\n",
    "#     # Display mask\n",
    "#     cv2.imshow(\"img_dilation\", img_dilation)\n",
    "#     try:\n",
    "#         # Display hand_crop\n",
    "#         cv2.imshow(\"hand_crop\", hand_crop)\n",
    "#     except:\n",
    "#         pass\n",
    "#     # Display foreground_display\n",
    "#     cv2.imshow(\"foreground_display\", foreground_display)\n",
    "    \n",
    "    \n",
    "#     k = cv2.waitKey(1) & 0xff\n",
    "    \n",
    "#     if k == 27: break # ESC pressed\n",
    "#     elif k == 114 or k == 112: \n",
    "#         # r pressed\n",
    "#         bg = frame.copy()\n",
    "#         bbox = bbox_initial\n",
    "#         tracking = -1\n",
    "#     elif k == 116:\n",
    "#         # t pressed\n",
    "#         # Initialize tracker with first frame and bounding box\n",
    "#         tracker = setup_tracker(2)\n",
    "#         tracking = tracker.init(frame, bbox)\n",
    "#     elif k == 115:\n",
    "#         # s pressed\n",
    "#         img_count += 1\n",
    "#         fname = os.path.join(DATA, CURR_POSE, \"{}_{}.jpg\".format(CURR_POSE, img_count))\n",
    "#         print(fname, hand_crop)\n",
    "#         cv2.imwrite(fname, hand_crop)\n",
    "#         print()\n",
    "#     elif k != 255: print(k)\n",
    "        \n",
    "# cv2.destroyAllWindows()\n",
    "# video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Neural Network\n",
    "\n",
    "Here we assemble the neural network with keras and compile it for training.\n",
    "\n",
    "This is a very simple convolutional neural network containing three convolutional and max pooling layers. After a tensor is passed through the convolutional layers, it is flatted into a vector and passed through the dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(54, 54, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data for Training\n",
    "\n",
    "Here we use the keras data generator to augment data. This loads data and applies certain transformations to it in order to improve generalization of the model.\n",
    "\n",
    "The ImageDataGenerator.flow_from_directory() is a convenience method that prepares classification data according to file directories.\n",
    "\n",
    "Training data is used to train the model to recognize gestures and validation data is used to verify that the model is not over fitting to the training data and the network is converging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(zoom_range=0.2, rotation_range=10)\n",
    "\n",
    "training_generator = training_datagen.flow_from_directory(\n",
    "    'training_data',\n",
    "    target_size=(54, 54),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    'validation_data',\n",
    "    target_size=(54, 54),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = load_img('training_data/swing/swing_111.jpg')  # this is a PIL image\n",
    "# x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "# x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# # the .flow() command below generates batches of randomly transformed images\n",
    "# # and saves the results to the `preview/` directory\n",
    "# i = 0\n",
    "# for batch in training_datagen.flow(x, batch_size=1,\n",
    "#                           save_to_dir='images/preview', save_prefix='fist', save_format='jpeg'):\n",
    "#     i += 1\n",
    "#     if i > 20:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Network\n",
    "\n",
    "Now we can train the model on the augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    generator=training_generator,\n",
    "    steps_per_epoch=2000 // batch_size,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=200 // batch_size,\n",
    "    workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Model History\n",
    "\n",
    "Reading in the model fitting output and plotting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "with open(MODEL_HISTORY) as history_file:\n",
    "    history = history_file.read()\n",
    "\n",
    "data = {}\n",
    "\n",
    "data['acc'] = re.findall(' acc: ([0-9]+\\.[0-9]+)', history)\n",
    "data['loss'] = re.findall(' loss: ([0-9]+\\.[0-9]+)', history)\n",
    "data['val_acc'] = re.findall(' val_acc: ([0-9]+\\.[0-9]+)', history)\n",
    "data['val_loss'] = re.findall(' val_loss: ([0-9]+\\.[0-9]+)', history)\n",
    "\n",
    "for key, values in data.items():\n",
    "    for i, val in enumerate(values):\n",
    "        values[i] = float(val)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(data['loss'])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(data['acc'])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(data['val_loss'])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(data['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"hand_model_gray.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completed Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_model = load_model(MODEL_FILE, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    0: 'fist',\n",
    "    1: 'five',\n",
    "    2: 'point',\n",
    "    3: 'swing'\n",
    "}\n",
    "\n",
    "# Set up tracker.\n",
    "def setup_tracker(ttype):\n",
    "    tracker_types = ['BOOSTING', 'MIL', 'KCF', 'TLD', 'MEDIANFLOW', 'GOTURN']\n",
    "    tracker_type = tracker_types[ttype]\n",
    "\n",
    "    if int(minor_ver) < 3:\n",
    "        tracker = cv2.Tracker_create(tracker_type)\n",
    "    else:\n",
    "        if tracker_type == 'BOOSTING':\n",
    "            tracker = cv2.TrackerBoosting_create()\n",
    "        if tracker_type == 'MIL':\n",
    "            tracker = cv2.TrackerMIL_create()\n",
    "        if tracker_type == 'KCF':\n",
    "            tracker = cv2.TrackerKCF_create()\n",
    "        if tracker_type == 'TLD':\n",
    "            tracker = cv2.TrackerTLD_create()\n",
    "        if tracker_type == 'MEDIANFLOW':\n",
    "            tracker = cv2.TrackerMedianFlow_create()\n",
    "        if tracker_type == 'GOTURN':\n",
    "            tracker = cv2.TrackerGOTURN_create()\n",
    "    \n",
    "    return tracker\n",
    "\n",
    "# Helper function for applying a mask to an array\n",
    "def mask_array(array, imask):\n",
    "    if array.shape[:2] != imask.shape:\n",
    "        raise Exception(\"Shapes of input and imask are incompatible\")\n",
    "    output = np.zeros_like(array, dtype=np.uint8)\n",
    "    for i, row in enumerate(imask):\n",
    "        output[i, row] = array[i, row]\n",
    "    return output\n",
    "\n",
    "\n",
    "# Begin capturing video\n",
    "video = cv2.VideoCapture(1)\n",
    "if not video.isOpened():\n",
    "    print(\"Could not open video\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# Read first frame\n",
    "ok, frame = video.read()\n",
    "if not ok:\n",
    "    print(\"Cannot read video\")\n",
    "    sys.exit()\n",
    "# Use the first frame as an initial background frame\n",
    "bg = frame.copy()\n",
    "\n",
    "\n",
    "# Kernel for erosion and dilation of masks\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "\n",
    "# Display positions (pixel coordinates)\n",
    "positions = {\n",
    "    'hand_pose': (15, 40), # hand pose text\n",
    "    'fps': (15, 20), # fps counter\n",
    "    'null_pos': (200, 200) # used as null point for mouse control\n",
    "}\n",
    "\n",
    "\n",
    "# Tracking\n",
    "# Bounding box -> (TopRightX, TopRightY, Width, Height)\n",
    "bbox_initial = (116, 116, 170, 170) # Starting position for bounding box\n",
    "bbox = bbox_initial\n",
    "# Tracking status, -1 for not tracking, 0 for unsuccessful tracking, 1 for successful tracking\n",
    "tracking = -1\n",
    "\n",
    "\n",
    "# Capture, process, display loop    \n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ok, frame = video.read()\n",
    "    display = frame.copy()\n",
    "    data_display = np.zeros_like(display, dtype=np.uint8) # Black screen to display data\n",
    "    if not ok:\n",
    "        break\n",
    "        \n",
    "        \n",
    "    # Start timer\n",
    "    timer = cv2.getTickCount()\n",
    "\n",
    "    \n",
    "    # Processing\n",
    "    # First find the absolute difference between the two images\n",
    "    diff = cv2.absdiff(bg, frame)\n",
    "    mask = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    # Threshold the mask\n",
    "    th, thresh = cv2.threshold(mask, 10, 255, cv2.THRESH_BINARY)\n",
    "    # Opening, closing and dilation\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    img_dilation = cv2.dilate(closing, kernel, iterations=2)\n",
    "    # Get mask indexes\n",
    "    imask = img_dilation > 0\n",
    "    # Get foreground from mask\n",
    "    foreground = mask_array(frame, imask)\n",
    "    foreground_display = foreground.copy()\n",
    "    \n",
    "    \n",
    "    # If tracking is active, update the tracker\n",
    "    if tracking != -1:\n",
    "        tracking, bbox = tracker.update(foreground)\n",
    "        tracking = int(tracking)\n",
    "        \n",
    "        \n",
    "    # Use numpy array indexing to crop the foreground frame\n",
    "    hand_crop = img_dilation[int(bbox[1]):int(bbox[1]+bbox[3]), int(bbox[0]):int(bbox[0]+bbox[2])]\n",
    "    try:\n",
    "        # Resize cropped hand and make prediction on gesture\n",
    "        hand_crop_resized = np.expand_dims(cv2.resize(hand_crop, (54, 54)), axis=0).reshape((1, 54, 54, 1))\n",
    "        prediction = hand_model.predict(hand_crop_resized)\n",
    "        predi = prediction[0].argmax() # Get the index of the greatest confidence\n",
    "        gesture = classes[predi]\n",
    "        \n",
    "        for i, pred in enumerate(prediction[0]):\n",
    "            # Draw confidence bar for each gesture\n",
    "            barx = positions['hand_pose'][0]\n",
    "            bary = 60 + i*60\n",
    "            bar_height = 20\n",
    "            bar_length = int(400 * pred) + barx # calculate length of confidence bar\n",
    "            \n",
    "            # Make the most confidence prediction green\n",
    "            if i == predi:\n",
    "                colour = (0, 255, 0)\n",
    "            else:\n",
    "                colour = (0, 0, 255)\n",
    "            \n",
    "            cv2.putText(data_display, \"{}: {}\".format(classes[i], pred), (positions['hand_pose'][0], 30 + i*60), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)\n",
    "            cv2.rectangle(data_display, (barx, bary), (bar_length, bary - bar_height), colour, -1, 1)\n",
    "        \n",
    "        cv2.putText(display, \"hand pose: {}\".format(gesture), positions['hand_pose'], cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        cv2.putText(foreground_display, \"hand pose: {}\".format(gesture), positions['hand_pose'], cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "    except Exception as ex:\n",
    "        cv2.putText(display, \"hand pose: error\", positions['hand_pose'], cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        cv2.putText(foreground_display, \"hand pose: error\", positions['hand_pose'], cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "    \n",
    "        \n",
    "    # Draw bounding box\n",
    "    p1 = (int(bbox[0]), int(bbox[1]))\n",
    "    p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "    cv2.rectangle(foreground_display, p1, p2, (255, 0, 0), 2, 1)\n",
    "    cv2.rectangle(display, p1, p2, (255, 0, 0), 2, 1)\n",
    "    \n",
    "    \n",
    "    # Move the mouse\n",
    "    hand_pos = ((p1[0] + p2[0])//2, (p1[1] + p2[1])//2)\n",
    "    mouse_change = ((p1[0] + p2[0])//2 - positions['null_pos'][0], positions['null_pos'][0] - (p1[1] + p2[1])//2)\n",
    "    # Draw mouse points\n",
    "    cv2.circle(display, positions['null_pos'], 5, (0,0,255), -1)\n",
    "    cv2.circle(display, hand_pos, 5, (0,255,0), -1)\n",
    "    cv2.line(display,positions['null_pos'],hand_pos,(255,0,0),5)\n",
    "    \n",
    "        \n",
    "    # Calculate Frames per second (FPS)\n",
    "    fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)\n",
    "    # Display FPS on frame\n",
    "    cv2.putText(foreground_display, \"FPS : \" + str(int(fps)), positions['fps'], cv2.FONT_HERSHEY_SIMPLEX, 0.65, (50, 170, 50), 2)\n",
    "    cv2.putText(display, \"FPS : \" + str(int(fps)), positions['fps'], cv2.FONT_HERSHEY_SIMPLEX, 0.65, (50, 170, 50), 2)\n",
    "    \n",
    "    \n",
    "    # Display result\n",
    "    cv2.imshow(\"display\", display)\n",
    "    # Display result\n",
    "    cv2.imshow(\"data\", data_display)\n",
    "    # Display diff\n",
    "    cv2.imshow(\"diff\", diff)\n",
    "    # Display thresh\n",
    "    cv2.imshow(\"thresh\", thresh)\n",
    "    # Display mask\n",
    "    cv2.imshow(\"img_dilation\", img_dilation)\n",
    "    try:\n",
    "        # Display hand_crop\n",
    "        cv2.imshow(\"hand_crop\", hand_crop)\n",
    "    except:\n",
    "        pass\n",
    "    # Display foreground_display\n",
    "    cv2.imshow(\"foreground_display\", foreground_display)\n",
    "    \n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    \n",
    "    if k == 27: break # ESC pressed\n",
    "    elif k == 114 or k == 108: \n",
    "        # r pressed\n",
    "        bg = frame.copy()\n",
    "        bbox = bbox_initial\n",
    "        tracking = -1\n",
    "    elif k == 116:\n",
    "        # t pressed\n",
    "        # Initialize tracker with first frame and bounding box\n",
    "        tracker = setup_tracker(2)\n",
    "        tracking = tracker.init(frame, bbox)\n",
    "    elif k == 115:\n",
    "        # s pressed\n",
    "        fname = os.path.join(\"data\", CURR_POS, \"{}_{}.jpg\".format(CURR_POS, get_unique_name(os.path.join(\"data\", CURR_POS))))\n",
    "        cv2.imwrite(fname, hand_crop)\n",
    "    elif k != 255: print(k)\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo video for those who cannot run it\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IJV11OGTNT8\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jrobchin_Computer-Vision-Basics-with-Python-Keras-and-OpenCV",
   "language": "python",
   "name": "jrobchin_computer-vision-basics-with-python-keras-and-opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
