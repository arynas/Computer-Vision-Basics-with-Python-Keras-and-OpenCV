{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Imports*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV Version: 4.2.0\n",
      "Keras image data format: channels_last\n"
     ]
    }
   ],
   "source": [
    "import sys # system functions (ie. exiting the program)\n",
    "import os # operating system functions (ie. path building on Windows vs. MacOs)\n",
    "\n",
    "import numpy as np # matrix operations (ie. difference between two matricies)\n",
    "import cv2 # (OpenCV) computer vision functions (ie. tracking)\n",
    "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "print('OpenCV Version: {}.{}.{}'.format(major_ver, minor_ver, subminor_ver))\n",
    "\n",
    "import matplotlib.pyplot as plt # (optional) for plotting and showing images inline\n",
    "%matplotlib inline\n",
    "\n",
    "import keras # high level api to tensorflow (or theano, CNTK, etc.) and useful image preprocessing\n",
    "from keras import backend as K\n",
    "print('Keras image data format: {}'.format(K.image_data_format()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting data\n",
    "\n",
    "The next objective is to recognize which gesture a hand is posed in. We will train our neural network on 4 gestures: fist, five, point and swing. For this network we will train the network on the mask to reduce dimensionality. Doing this makes it a more simple problem for the network to model, while sacrificing information stored in the colours of an image.\n",
    "\n",
    "Here, we track our hand with the background subtracted and thresholded. Everytime you hit 's' a screen capture of your cropped hand is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classes = {\n",
    "    0: 'fist',\n",
    "    1: 'five',\n",
    "    2: 'point',\n",
    "    3: 'swing'\n",
    "}\n",
    "\n",
    "CURR_POSE = 'five'\n",
    "DATA = 'training_data'\n",
    "\n",
    "# Helper function for applying a mask to an array\n",
    "def mask_array(array, imask):\n",
    "    if array.shape[:2] != imask.shape:\n",
    "        raise Exception(\"Shapes of input and imask are incompatible\")\n",
    "    output = np.zeros_like(array, dtype=np.uint8)\n",
    "    for i, row in enumerate(imask):\n",
    "        output[i, row] = array[i, row]\n",
    "    return output\n",
    "\n",
    "# Set up tracker.\n",
    "def setup_tracker(ttype):\n",
    "    tracker_types = ['BOOSTING', 'MIL', 'KCF', 'TLD', 'MEDIANFLOW', 'GOTURN']\n",
    "    tracker_type = tracker_types[ttype]\n",
    "\n",
    "    if tracker_type == 'BOOSTING':\n",
    "        tracker = cv2.TrackerBoosting_create()\n",
    "    if tracker_type == 'MIL':\n",
    "        tracker = cv2.TrackerMIL_create()\n",
    "    if tracker_type == 'KCF':\n",
    "        tracker = cv2.TrackerKCF_create()\n",
    "    if tracker_type == 'TLD':\n",
    "        tracker = cv2.TrackerTLD_create()\n",
    "    if tracker_type == 'MEDIANFLOW':\n",
    "        tracker = cv2.TrackerMedianFlow_create()\n",
    "    if tracker_type == 'GOTURN':\n",
    "        tracker = cv2.TrackerGOTURN_create()\n",
    "\n",
    "    return tracker\n",
    "\n",
    "# Begin capturing video\n",
    "video = cv2.VideoCapture(1)\n",
    "if not video.isOpened():\n",
    "    print(\"Could not open video\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# Read first frame\n",
    "ok, frame = video.read()\n",
    "if not ok:\n",
    "    print(\"Cannot read video\")\n",
    "    sys.exit()\n",
    "# Use the first frame as an initial background frame\n",
    "bg = frame.copy()\n",
    "\n",
    "\n",
    "# Kernel for erosion and dilation of masks\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "\n",
    "# Tracking\n",
    "# Bounding box -> (TopRightX, TopRightY, Width, Height)\n",
    "bbox_initial = (60, 60, 170, 170)\n",
    "bbox = bbox_initial\n",
    "# Tracking status, -1 for not tracking, 0 for unsuccessful tracking, 1 for successful tracking\n",
    "tracking = -1\n",
    "\n",
    "\n",
    "# Text display positions\n",
    "positions = {\n",
    "    'hand_pose': (15, 40),\n",
    "    'fps': (15, 20)\n",
    "}\n",
    "\n",
    "\n",
    "# Image count for file name\n",
    "img_count = 0\n",
    "\n",
    "# Capture, process, display loop    \n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ok, frame = video.read()\n",
    "    display = frame.copy()\n",
    "    if not ok:\n",
    "        break\n",
    "        \n",
    "        \n",
    "    # Start timer\n",
    "    timer = cv2.getTickCount()\n",
    "\n",
    "    \n",
    "    # Processing\n",
    "    # First find the absolute difference between the two images\n",
    "    diff = cv2.absdiff(bg, frame)\n",
    "    mask = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    # Threshold the mask\n",
    "    th, thresh = cv2.threshold(mask, 10, 255, cv2.THRESH_BINARY)\n",
    "    # Opening, closing and dilation\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    img_dilation = cv2.dilate(closing, kernel, iterations=2)\n",
    "    # Get mask indexes\n",
    "    imask = img_dilation > 0\n",
    "    # Get foreground from mask\n",
    "    foreground = mask_array(frame, imask)\n",
    "    foreground_display = foreground.copy()\n",
    "    \n",
    "    \n",
    "    # If tracking is active, update the tracker\n",
    "    if tracking != -1:\n",
    "        tracking, bbox = tracker.update(foreground)\n",
    "        tracking = int(tracking)\n",
    "        \n",
    "        \n",
    "    # Use numpy array indexing to crop the foreground frame\n",
    "    hand_crop = img_dilation[int(bbox[1]):int(bbox[1]+bbox[3]), int(bbox[0]):int(bbox[0]+bbox[2])]\n",
    "    \n",
    "        \n",
    "    # Draw bounding box\n",
    "    p1 = (int(bbox[0]), int(bbox[1]))\n",
    "    p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "    cv2.rectangle(foreground_display, p1, p2, (255, 0, 0), 2, 1)\n",
    "    cv2.rectangle(display, p1, p2, (255, 0, 0), 2, 1)\n",
    "    \n",
    "        \n",
    "    # Calculate Frames per second (FPS)\n",
    "    fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)\n",
    "    # Display FPS on frame\n",
    "    cv2.putText(foreground_display, \"FPS : \" + str(int(fps)), positions['fps'], cv2.FONT_HERSHEY_SIMPLEX, 0.65, (50, 170, 50), 2)\n",
    "    cv2.putText(display, \"FPS : \" + str(int(fps)), positions['fps'], cv2.FONT_HERSHEY_SIMPLEX, 0.65, (50, 170, 50), 2)\n",
    "    \n",
    "    \n",
    "    # Display result\n",
    "    cv2.imshow(\"display\", display)\n",
    "    # Display diff\n",
    "    cv2.imshow(\"diff\", diff)\n",
    "    # Display thresh\n",
    "    cv2.imshow(\"thresh\", thresh)\n",
    "    # Display mask\n",
    "    cv2.imshow(\"img_dilation\", img_dilation)\n",
    "    try:\n",
    "        # Display hand_crop\n",
    "        cv2.imshow(\"hand_crop\", hand_crop)\n",
    "    except:\n",
    "        pass\n",
    "    # Display foreground_display\n",
    "    cv2.imshow(\"foreground_display\", foreground_display)\n",
    "    \n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    \n",
    "    if k == 27: break # ESC pressed\n",
    "    elif k == 114 or k == 112: \n",
    "        # r pressed\n",
    "        bg = frame.copy()\n",
    "        bbox = bbox_initial\n",
    "        tracking = -1\n",
    "    elif k == 116:\n",
    "        # t pressed\n",
    "        # Initialize tracker with first frame and bounding box\n",
    "        tracker = setup_tracker(2)\n",
    "        tracking = tracker.init(frame, bbox)\n",
    "    elif k == 115:\n",
    "        # s pressed\n",
    "        img_count += 1\n",
    "        fname = os.path.join(DATA, CURR_POSE, \"{}_{}.jpg\".format(CURR_POSE, img_count))\n",
    "        print(fname, hand_crop)\n",
    "        cv2.imwrite(fname, hand_crop)\n",
    "        print()\n",
    "    elif k != 255: print(k)\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jrobchin_Computer-Vision-Basics-with-Python-Keras-and-OpenCV",
   "language": "python",
   "name": "jrobchin_computer-vision-basics-with-python-keras-and-opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
